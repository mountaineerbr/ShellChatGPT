# ~/.chatgpt.conf
# Config file for chatgpt.sh v0.83
# These have higher priority than environment
# Unset variables use defaults
# 

# API keys
#OPENAI_API_KEY=
#GOOGLE_API_KEY=
#MISTRAL_API_KEY=
#GROQ_API_KEY=
#ANTHROPIC_API_KEY=
#GITHUB_TOKEN=

# DEFAULTS
# Text cmpls model
#MOD="gpt-3.5-turbo-instruct"

# Chat cmpls model
#MOD_CHAT="gpt-4o"  #"chatgpt-4o-latest"

# Image model (generations)
#MOD_IMAGE="dall-e-3"

# Whisper model (STT)
#MOD_AUDIO="whisper-1"
#MOD_AUDIO_GROQ="whisper-large-v3"

# Speech model (TTS)
#MOD_SPEECH="tts-1"

# LocalAI model
#MOD_LOCALAI="phi-2"

# Ollama model
#MOD_OLLAMA="llama3"

# Google AI model
#MOD_GOOGLE="gemini-1.5-pro-latest"

# Mistral AI model
#MOD_MISTRAL="mistral-large-latest"

# Groq model
#MOD_GROQ="llama-3.1-70b-versatile"
# Enable Groq Whisper only
#WHISPER_GROQ=

# Anthropic model
#MOD_ANTHROPIC="claude-3-5-sonnet-latest"

# Github Azure model
#MOD_GITHUB="Phi-3-medium-128k-instruct"

# Bash readline mode
#READLINEOPT="emacs"  #"vi"

# Stream response
#STREAM=1

# Prompter flush with <CTRL-D>
#OPTCTRD=

# Temperature
#OPTT=0

# Whisper temperature
#OPTTW=0

# Top_p probability mass (nucleus sampling)
#OPTP=1

# Top_k (localai, ollama, google ai)
#OPTK=

# Maximum response tokens
#OPTMAX=1024

# Model capacity (auto)
#MODMAX=

# Presence penalty
#OPTA=

# Frequency penalty
#OPTAA=

# N responses of Best_of
#OPTB=

# Number of responses
#OPTN=1

# Keep Alive (seconds, Ollama)
#OPT_KEEPALIVE=

# Seed (integer)
#OPTSEED=

# Set python tiktoken
#OPTTIK=

# Text editor
#VISUAL="vim"

# Image size
#OPTS=1024x1024  #1024x1024hd

#Image style
#OPTI_STYLE=  #natural, vivid

# Image out format
#OPTI_FMT=b64_json  #url

# TTS voice
#OPTZ_VOICE="echo"  #alloy, fable, onyx, nova, and shimmer

# TTS voice speed
#OPTZ_SPEED=   #0.25 - 4.0

# TTS out format
#OPTZ_FMT="opus"  #mp3, opus, aac, flac

# Recorder command, e.g. "sox -d"
#REC_CMD=""

# Media player command, e.g. "cvlc"
#PLAY_CMD=""

# Clipboard set command, e.g. "xsel -b", "pbcopy"
#CLIP_CMD=""

# Markdown option and renderer
# e.g. "pygmentize -s -lmd", "glow", "mdless", "mdcat"
#OPTMD=0
#MD_CMD="bat"

# Fold response (wrap at white spaces)
#OPTFOLD=1

# Avoid using dialog
#NO_DIALOG=

# Restart sequence (text or null)
#RESTART='\nQ: '
#
# Start sequence (text or null)
#START='\nA:'
# *Chat mode of text completions only*

# Input and output prices
# (dollars per million tokens)
#MOD_PRICE="2.5 10"

# Currency rate against USD
# e.g. 1 USD is worth 5.66 BRL or 153.248 JPY
#CURRENCY_RATE="1"


# Model Instruction (chat and text completions)
#
#INSTRUCTION_CHAT="The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and friendly."
#INSTRUCTION_CHAT="A seguinte é uma conversa com um assistente de IA. O assistente é prestativo, criativo, inteligente e muito amigável."  #portuguese
#INSTRUCTION_CHAT="Lo siguiente es una conversación con un asistente de IA. El asistente es servicial, creativo, inteligente y muy amigable."  #spanish
#INSTRUCTION_CHAT="Ce qui suit est une conversation avec un assistant d'IA. L'assistant est serviable, créatif, intelligent et très amical."  #french
#INSTRUCTION_CHAT="Das Folgende ist ein Gespräch mit einem KI-Assistenten. Der Assistent ist hilfsbereit, kreativ, klug und sehr freundlich."  #german
#INSTRUCTION_CHAT="以下は、AIアシスタントとの会話です。アシスタントは、親切で、創造的で、賢く、そしてとてもフレンドリーです。"  #japanese
#INSTRUCTION_CHAT="以下是对话内容与一位人工智能助手之间的对话。该助手乐于助人、富有创造力、聪明且非常友好。"  #chinese
#INSTRUCTION_CHAT="以下是对话内容與一位人工智慧助手之間的對話。該助手樂於助人、富有創造力、聰明且非常友善。"  #chinese traditional
#
#INSTRUCTION=


# CACHE AND OUTPUT DIRECTORIES
#CACHEDIR="$HOME/.cache/chatgptsh"
#OUTDIR="$HOME/Downloads"

# Bash history size
#HISTSIZE=256

# Host API URLs
#OPENAI_URL_PATH="https://api.openai.com/v1/chat/completions"  #disable endpoint auto-selection
#OPENAI_BASE_URL="https://api.openai.com/v1";
#OLLAMA_BASE_URL="http://localhost:11434";
#LOCALAI_BASE_URL="http://127.0.0.1:8080/v1";
#MISTRAL_BASE_URL="https://api.mistral.ai/v1";
#GOOGLE_BASE_URL="https://generativelanguage.googleapis.com/v1beta";
#GROQ_BASE_URL="https://api.groq.com/openai/v1";
#ANTHROPIC_BASE_URL="https://api.anthropic.com/v1";
#GITHUB_BASE_URL="https://models.inference.ai.azure.com";


# COLOR THEMES
# Classic Console (v0.2)
#Color11="${Bold}"      Color10=              # system, \u001b[1;37m
#Color9="${BCyan}"      Color8="${Cyan}"      # user input
#Color7="${On_Purple}"  Color6="${BPurple}"   Color5="${Purple}"  # whisper
#Color4="${Bold}"       Color3=               # response
#Color2="${BRed}"       Color1="${Red}"       # warning / error

# Theme 1.1 - Sunset Glow
#Color11="${BRed}" Color10="${BRed}" Color9="${Purple}" Color8="${BPurple}" Color7="${On_Yellow}" Color6="${Cyan}" Color5="${BCyan}" Color4="${Green}" Color3="${BGreen}" Color2="${Blue}" Color1="${BBlue}"

# Theme 2.1 - Radium Tides
#Color11="${BBlue}${On_White}" Color10="${Blue}${On_White}" Color9="${BRed}" Color8="${Red}" Color7="${BWhite}${On_Blue}" Color6="${BGreen}" Color5="${Green}" Color4="${BPurple}${On_Blue}" Color3="${Purple}${On_Blue}" Color2="${White}${On_Red}" Color1="${BWhite}${On_Red}"

# Theme 3.2 - Midnight Oasis
#Color11="${On_Purple}" Color10="${BWhite}${On_Purple}" Color9="${Cyan}" Color8="${BBlue}" Color7="${On_Blue}" Color6="${BYellow}${On_Blue}" Color5="${Yellow}${On_Blue}" Color4="${White}" Color3="${BWhite}" Color2="${BWhite}${On_Red}" Color1="${On_Red}"
